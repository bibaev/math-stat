---
title: "R Notebook"
output: html_notebook
---

# Семинар 4

## Задача 1
Зададим используемые константы
``` {r parameters}
a0 = 0
a1 = 2
variance = 5
n = 30
```

Проведем моделирование, выведем требуемый график
``` {r}
fun_t = function(sample, h0) {
  n = length(sample)
  sd = sqrt(var(sample))
  mean = mean(sample)
  return(sqrt(n) * (mean - h0) / sd)
}

T1 = c()
T2 = c()

for (i in 1:100) {
  sample1 = rnorm(n, mean = a0, sd = sqrt(variance))
  sample2 = rnorm(n, mean = a1, sd = sqrt(variance))
  
  T1[i] = fun_t(sample1, a0)
  T2[i] = fun_t(sample2, a0)
}

x = seq(-15, 15, 0.01)
hist(T1, xlim = c(-3, 12), ylim = c(0, 0.6), freq = F, col = rgb(0, 1, 0, 0.3))
hist(T2, add = T, freq = F, col = rgb(1, 0, 0, 0.3))
lines(x,dt(x,df=n-1),col="green")
```

### Вопросы
* График плотности T-cтатистики по какой выборке совпал с распределением Стьюдента?

По выборке с тем же ожиданием, что и в гипотезе.

* Где на графиках ошибки 1 и 2 рода? (опишите словами)

Первого рода: хвосты зеленого графика, площадь под которыми в сумме равна $\alpha$

Второго рода: Площадь пересечением центральной области под зеленым графиков (без хвостов) и области под красным графиком.

## Задача 2
Зададим используемые константы
``` {r}
mu0 = 0
mu1 = 1
h0 = mu0
h1 = mu1
sd = 3
alpha = 0.05
gamma = 0.99
```

Нужно посчитать сколько раз случилась ошибка первого рода и сколько раз случилась ошибка второго рода.

``` {r modeling}
experiment = function(n, sd, mu, h_mu) {
  accept = 0
  decline = 0
  for(i in 1:1000) {
    sample = rnorm(n = n, mean = mu, sd = sd)
    p_value = t.test(sample,alternative=c("t"),mu=h_mu)$p.value
    if(p_value > alpha) {
      accept = accept + 1
    }
    else {
      decline = decline + 1
    }
  }
  
  return(data.frame(accept = accept, decline = decline))
}

res1 = experiment(100, sd, mu = mu0, h_mu = mu0)
res2 = experiment(100, sd, mu = mu1, h_mu = mu0)
print(res1)
print(res2)
```

Оценка для ошибки первого рода 
```{r}
print(res1$decline / (res1$accept + res1$decline))
```

Оценка для ошибки второго рода
```{r}
beta = res2$accept / (res2$accept + res2$decline)
print(beta)
```

Оценка для мощности критерия
```{r}
print(1 - beta)
```

Определим размер выборки для требуемой мощности критерия.
```{r}
power = function(result) {
  beta = result$accept / (result$accept + result$decline)
  return(1 - beta)
}

n = 100
p = power(experiment(n, sd = sd, mu = mu1, h_mu = mu0))
while(p < gamma) {
  n = n + 1
  p = power(experiment(n, sd = sd, mu = mu1, h_mu = mu0))
  print(paste("N = ", n, "power = ", p))
}

print(paste("Answer:", n))
```


Построим зависимость мощности от размера выборки
```{r}
sd = 6
ns = c(10, 50, 100, 150, 200, 250, 300, 400, 600, 800, 1000)
powers = c()
i = 1
for(n in ns) {
  powers[i] = power(experiment(n, sd = sd, mu = mu1, h_mu = mu0))
  i = i + 1
}

plot(ns, powers, type = 'l', main = 'power by sample size', xlab = "N", ylab = "Power")
```

Построим зависимость мощности от вычилины стандартного отклонения
```{r}
n = 100
power = function(result) {
  beta = result$accept / (result$accept + result$decline)
  return(1 - beta)
}
sds = c(1,2,3,4,5,6,7,8, 10, 15)
powers = c()
i = 1
for(sd in sds) {
  powers[i] = power(experiment(n, sd = sd, mu = mu1, h_mu = mu0))
  i = i + 1
}

plot(sds, powers, type = 'l', main = 'power by sd', xlab = "sd", ylab = "Power")
```


### Вопросы
* Как зависит мощность от объёма выборки и дисперсии?

С ростом объема выборки мощность критерия растет. С ростом объема выборки дисперсия критерия уменьшается, поэтому и ошибка при проверке гипотезы уменьшается.

Чем меньше дисперсия, тем больше мощность. Вполне естественно, что чем меньше дисперсия исходной генеральной савокупности, тем меньше дисперсия критерия, тем сложнее ошибиться при проверке гипотез.
