---
title: "homework9"
output: html_document
---

## Задания с первых шагов.
Читаем данные:
```{r}
data = read.table("data/logit_data.txt", header = T)
head(data)
```
Пол - это категориальный фактор
```{r}
data$sex = factor(data$sex)
```

Бинаризуем занчения `sbp`
```{r}
data$sbp_bin = sapply(data$sbp, function(x) {return (x > 140)})
head(data)
```


Построим по ним логистическую регрессию
```{r}
model = glm(formula = sbp_bin ~ sex + age + bmi, data = data, family =binomial(link='logit')) 
summary(model)
```
```{r}
prob=predict(model,type=c("response"))
data$prob=prob
library(pROC)
g <- roc(sbp_bin ~ prob, data = data)
print(g$auc)
```

## Задание с последнего шага
С помощью моделирования проведите сравнение МНК оценок и оценок ридж регрессии.

Для этого 

* задайте нормально распределенную случайную величину $\xi_1, E\xi_1\neq0$ 
```{r}
xi1 = function(n) {
  return(rnorm(n, mean = -3, sd = 1))
}
```

* задайте нормально распределенную случайную величину $\xi_2=0.98\xi_1$
```{r}
xi2 = function(xi1) {
  return(0.98 * xi1)
}
```

* задайте нормально распределенную случайную величину $\xi_3, E\xi_3 \neq 0$
```{r}
xi3 = function(n) {
  return(rnorm(n, mean = 5, sd = 2))
}
```

* задайте нормально распределенную случайную величину $\varepsilon, E\varepsilon = 0, D\varepsilon < 10 D\xi_1, D\varepsilon < 10D\xi_3$
```{r}
epsilon = function(n) {
  return(rnorm(n, mean = 0, sd = 3))
}
```

Задайте истинные значения параметров $β_0,  β_1, β_2, β_3$.
```{r}
b0 = 0
b1 = 1
b2 = 2
b3 = 3
```


Задайте случайную величину $η=β_0+β_1ξ_1+β_2ξ_2+β_3ξ_3+ε$
```{r}
eta = function(xi1, xi2, xi3, eps) {
  return(b0 + b1 * xi1 + b2 * xi2 + b3 * xi3 + eps)
}
```


Смоделируйте выборку объемом 100 из случайного вектора $(η,ξ_1,ξ_2,ξ_3)$
```{r}
sample = function(n) {
  first = xi1(n)
  second = xi2(first)
  third = xi3(n)
  eps = epsilon(n)
  return(matrix(data = c(eta(first, second, third, eps), first, second, third), nrow = n, ncol = 4))
}
```

```{r}
data = sample(100)
print(head(data))
```


На основе полученной выборки найдите МНК оценки и ридж-оценки параметров $β_0,β_1,β_2,β_3$.
```{r}
model = glm(formula = data[, 1] ~ data[, 2] + data[, 3] + data[, 4])
summary(model)
```

```{r}
library(MASS)
ridge = lm.ridge(formula = data[, 1] ~ data[, 2] + data[, 3] + data[, 4], lambda = 0.0001)
ridge
```
```{r}
ridge = lm.ridge(formula = data[, 1] ~ data[, 2] + data[, 3] + data[, 4], lambda = 10)
ridge
```


Попробуйте 2 разных параметра ридж-регрессии.

Повторите моделирование 1000 раз. Постройте боксплоты оценок. Сравните полученные оценки с истинными значениями параметров. Сделайте выводы