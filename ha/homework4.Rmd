---
title: "homework4"
output: html_document
---

Задайте произвольным образом математическое ожидание $a_0$ и среднеквадратическое отклонение $\sigma_0$ нормального распределения, задайте вероятность ошибки первого рода $\alpha$ и вероятность ошибки второго рода $\beta$, задайте значение $a_1: a_1 < a_0$.
```{r}
a0 = 10
sd = 3
alpha = 0.01
beta = 0.05
a1 = a0 - sd / 3

MODELING_ITERATIONS_COUNT = 1000
```

1. Найдите объем выборки $n$, при котором вероятности ошибок первого и второго рода при использовании критерия Неймана-Пирсона не превзойдут выбранных значений $\alpha$ и $\beta$.
```{r}
u_alpha = qnorm(1 - alpha)
u_beta = qnorm(beta)
n = floor((sd^2 * (u_alpha - u_beta)^2) / (a0 - a1)^2)
print(n)
```

2. Оцените вероятность ошибки первого рода с помощью моделирования. Для этого смоделируйте выборку объема $n$ из распределения $N(a_0,\sigma_0)$. Примените критерий для проверки гипотезы $H_0: a = a_0$ при альтернативе $H_1: a = a_1$, считая $\sigma_0$ известным.
```{r}
accept = 0
u = qnorm(alpha)
for(i in 1:MODELING_ITERATIONS_COUNT) {
  sample = rnorm(n, a0, sd)
  z = sqrt(n) * (mean(sample) - a0) / sd
  if (z >= u) {
    accept = accept + 1
  }
}

print(paste("First type error =", round(1 - accept / MODELING_ITERATIONS_COUNT, 3)))
```

3. Оцените вероятность ошибки второго рода с помощью моделирования. Для этого смоделируйте выборку объема $n$ из распределения $N(a_1,\sigma_0)$. Примените критерий для проверки гипотезы $H_0: a = a_0$ при альтернативе $H_1: a = a_1$, считая $\sigma_0$ известным.
```{r}
accept = 0
u = qnorm(alpha)
for(i in 1:MODELING_ITERATIONS_COUNT) {
  sample = rnorm(n, a1, sd)
  z = sqrt(n) * (mean(sample) - a0) / sd
  if (z >= u) {
    accept = accept + 1
  }
}

print(paste("Second type error =", round(accept / MODELING_ITERATIONS_COUNT, 3)))
```

4. Постройте критерий с вероятностью ошибки первого рода $\alpha$ для проверки гипотезы $H_0:a = a_0$ при альтернативе $H_1: a\neq a_0$, считая  $\sigma_0$ известным. Оцените вероятность ошибки второго рода (зная какие истинные были значения параметров).
```{r}
accept = 0
u_left = qnorm(alpha / 2)
u_right = qnorm(1 - alpha / 2)
for(i in 1:MODELING_ITERATIONS_COUNT) {
  sample = rnorm(n, a0, sd)
  z = sqrt(n) * (mean(sample) - a0) / sd
  if(z >= u_left && z <= u_right){
    accept = accept + 1
  }
}

print(paste("First type error =", round(1 - accept / MODELING_ITERATIONS_COUNT, 3)))
```


5. Постройте критерий с вероятностью ошибки первого рода α для проверки гипотезы $H_0: a = a_0$ при альтернативе $H_1: a \neq a_0$, считая  $\sigma_0$ *НЕизвестным*. Оцените вероятность ошибки второго рода (зная какие истинные были значения параметров). 
```{r}
accept = 0
t_left = qt(p = alpha / 2, df = n - 1)
t_right = qt(p = 1 - alpha / 2, df = n - 1)
for(i in 1:MODELING_ITERATIONS_COUNT) {
  sample = rnorm(n, a0, sd)
  s = sqrt(var(sample) * (n - 1) / n)
  z = sqrt(n) * (mean(sample) - a0) / s
  if(z >= t_left && z <= t_right){
    accept = accept + 1
  }
}

print(paste("First type error =", round(1 - accept / MODELING_ITERATIONS_COUNT, 3)))
```

6. Сделайте выводы
* Чем ближе значения a_0, a_1, тем больше должен быть размер выборки, чтобы проверять гипотезы с заданным уровнями ошибок первого и второго рода. Это вполне ожидаемо, т.к. чем ближе они, тем сложнее ошибиться.
* Хотелось сказать, что если $\sigma_0$ неизвестна, то вероятность ошибки первого рода выше. Но это не так. Возможно причина в большом размере выборки, который привел к тому, что выборочное среднее очень близко к истинному, а распределение стьюдента с таким большим количеством степеней свободы почти совпало со стандартным нормальным растределением, поэтому разницы нет.
* Разницы в вероятностях ошибиться в зависимости от вида альтернативной гипотезы не замечено.
